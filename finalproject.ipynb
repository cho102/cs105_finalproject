{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1612c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from math import pi\n",
    "import seaborn as sns\n",
    "\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379ebaff",
   "metadata": {},
   "source": [
    "# Clean Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6523c81",
   "metadata": {},
   "source": [
    "The data that is used in this project is the yelp dataset. We only selected boba shops for the business dataset and concatenated it with the reviews for each given business."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799b8ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"yelp_reviews_boba_categories.csv\")\n",
    "#Created a new column called sentiment to group positive, negative and neutral \n",
    "df.loc[(df[\"stars\"] >= 4, \"Sentiment\")] = 'Positive'\n",
    "df.loc[(df[\"stars\"] == 3, \"Sentiment\")] = 'Neutral'\n",
    "df.loc[(df[\"stars\"] == 3.5, \"Sentiment\")] = 'Neutral'\n",
    "df.loc[(df[\"stars\"] <= 2.5, \"Sentiment\")] = 'Negative'\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91ab7e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648d1946",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df.business_id.unique())) #Prints how many businesses are in the clean dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460ad1d1",
   "metadata": {},
   "source": [
    "# EDA for the Clean Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec034f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total number of reviews for each restaurant\n",
    "reviewsCount = df.groupby(\"name\")[\"stars\"].count()\n",
    "plt.figure().set_figwidth(20)\n",
    "plt.bar(reviewsCount.index,reviewsCount)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ecb020",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribution of star ratings in dataframe\n",
    "df.groupby(['review_stars']).count().plot(kind='pie', y='text', ylabel=\"Review Ratings\", autopct='%1.0f%%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec81aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(len(df.attributes)):\n",
    "print(len(df.attributes))\n",
    "df['attributes'] = df['attributes'].astype(str)\n",
    "df.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec0ea9d",
   "metadata": {},
   "source": [
    "This graph shows the relationship between the cost of Wi-Fi and the star rating given by the user. We can see that since there are more lower ratings when Wi-Fi is not free that there could be a relationship between cost of Wi-Fi and the star rating given by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c951d42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df.attributes)):\n",
    "    if df.attributes[i][12:16] == 'free':\n",
    "        df.loc[i,'wifi'] = \"Wi-Fi is free\"\n",
    "    else:\n",
    "        df.loc[i,'wifi'] = \"Wi-Fi is not free\"\n",
    "sns.boxplot(x='wifi', y='stars', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1818f460",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df.attributes)):\n",
    "    if \"'RestaurantsTakeOut': 'True'\" in df.attributes[i]:\n",
    "        df.loc[i,'take-out'] = \"Yes\"\n",
    "    else:\n",
    "        df.loc[i,'take-out'] = \"No\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece4ba46",
   "metadata": {},
   "source": [
    "This graph shows the relationship between restaurant take-out and the star rating given by the user. We can see that most of the restaurants have take-out and have significantly good ratings given by user. The restaurants that don't have take-out also have similar distribution. Therefore, restaurant take-out does not have much effect on the star rating given by the user. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab8eb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.groupby(['take-out','stars']).size()\n",
    "df2 = df2.unstack()\n",
    "df2.plot(kind=\"barh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6669265e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewsCount = df.groupby(\"city\")[\"stars\"].count()\n",
    "plt.figure().set_figwidth(20)\n",
    "plt.bar(reviewsCount.index,reviewsCount)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc432e0d",
   "metadata": {},
   "source": [
    "The bar graph shows the distribution of places with boba on yelp based on cities in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda8b613",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewsCount = df.groupby(\"state\")[\"stars\"].count()\n",
    "plt.figure().set_figwidth(20)\n",
    "plt.bar(reviewsCount.index,reviewsCount)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657e94d4",
   "metadata": {},
   "source": [
    "The bar graph shows the distribution of places with boba on yelp based on states in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ad4784",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['stars']).count().plot(kind='pie', y='text', ylabel=\"Review Stars\", autopct='%1.0f%%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f9f701",
   "metadata": {},
   "source": [
    "These is the distribution of review stars rounded to the half-stars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42efb580",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['stars'], kde=False); #distribution of stars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36f675c",
   "metadata": {},
   "source": [
    "This visualization shows the average amount of stars across all boba businesses. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277012f2",
   "metadata": {},
   "source": [
    "# Text Mining with Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54364e83",
   "metadata": {},
   "source": [
    "Using linear regression, we are trying to predict whether a review is negative or positive and what rating the user will give for that business. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac459b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#natural language toolkit\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import FreqDist\n",
    "from sklearn import metrics, neighbors\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad4a952",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f571e66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#displaying a dataframe that only contains the reviews, sentiment, and star ratings\n",
    "display(df[['text', 'Sentiment','stars']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7a60bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#length of each review, made new length column at end to see num of charcaters in review\n",
    "df['length'] = df['text'].apply(len)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac159eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize length of review vs star number rating\n",
    "sns.boxplot(x='stars', y='length', data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9631551f",
   "metadata": {},
   "source": [
    "The above boxlpot shows the visualization of length of characters in a review vs the respective star rating. We can see that shorter lengthed reviews tend to have a lower star rating compared to higher star rated reviews. However, this might be because there are less negative ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411fe68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "full_text = ' '.join(df['text'])\n",
    "#convert reviews to lowercase\n",
    "lower_full_text = full_text.lower()\n",
    "#tokenize words and put into a list\n",
    "word_tokens = word_tokenize(lower_full_text)\n",
    "tokens = list()\n",
    "\n",
    "#if the word is a character and is not a stop word, append to list, then find freq of tokens\n",
    "for word in word_tokens:\n",
    "    if word.isalpha() and word not in stopwords.words('english'):\n",
    "        tokens.append(word)\n",
    "token_dist = FreqDist(tokens)\n",
    "dist = pd.DataFrame(token_dist.most_common(30),columns=['Word', 'Frequency'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e4af00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#distribution of frequent unique words in reviews\n",
    "print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdb1bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new df with only stars, type of review, and reviews\n",
    "starsdf = pd.DataFrame(df[['stars','Sentiment','text']])\n",
    "starsdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a9de5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#categorical to numerical data for sentinent\n",
    "starsdf['Sentiment'].replace(['Negative', 'Positive', 'Neutral'],\n",
    "                        [2, 1, 0], inplace=True)\n",
    "starsdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740e2c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#analyze each sentiment (pos(1), neutral(0), neg(2))\n",
    "print('Number of positive reviews: ', starsdf['Sentiment'].value_counts()[1])\n",
    "print('Number of negative reviews: ', starsdf['Sentiment'].value_counts()[2])\n",
    "print('Number of neutral reviews: ', starsdf['Sentiment'].value_counts()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460b98a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7212 rows = 7212 positive reviews, as seen from above\n",
    "#make df with only positive reviews\n",
    "pos = starsdf.loc[starsdf['Sentiment'] == 1]\n",
    "posrev = pd.DataFrame(pos[['stars','Sentiment','text']])\n",
    "len(pos.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a05c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make df with only neutral reviews\n",
    "neu = starsdf.loc[starsdf['Sentiment'] == 0]\n",
    "neurev = pd.DataFrame(neu[['stars','Sentiment','text']])\n",
    "len(neu.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44792eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make df with only negative reviews\n",
    "neg = starsdf.loc[starsdf['Sentiment'] == 2]\n",
    "negrev = pd.DataFrame(neg[['stars','Sentiment','text']])\n",
    "len(neg.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512e97d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df with positive and negative reviews\n",
    "posneg = starsdf.loc[(starsdf['Sentiment'] == 1) | (starsdf['Sentiment'] == 2)]\n",
    "posnegrev = pd.DataFrame(posneg[['stars','Sentiment','text']])\n",
    "len(posneg.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e78a283",
   "metadata": {},
   "source": [
    "We will be using the dataframe above to decipher between strictly positive and negative reviews when testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d02724",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data classification\n",
    "X = posneg['text']\n",
    "y = posneg['stars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0238bc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove punctuation in reviews\n",
    "def rm(text):\n",
    "    nopunc = [char for char in text if char not in string.punctuation]\n",
    "    nopunc = ''.join(nopunc)\n",
    "    return [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6e9433",
   "metadata": {},
   "outputs": [],
   "source": [
    "#word freq in pos reviews\n",
    "full_text = ' '.join(pos['text'])\n",
    "#convert reviews to lowercase\n",
    "lower_full_text = full_text.lower()\n",
    "#tokenize words and put into a list\n",
    "word_tokens = word_tokenize(lower_full_text)\n",
    "tokens = list()\n",
    "\n",
    "#if the word is a character and is not a stop word, append to list, then find freq of tokens\n",
    "for word in word_tokens:\n",
    "    if word.isalpha() and word not in stopwords.words('english'):\n",
    "        tokens.append(word)\n",
    "token_dist = FreqDist(tokens)\n",
    "dist = pd.DataFrame(token_dist.most_common(10),columns=['Word', 'Frequency'])\n",
    "print(dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97a33fb",
   "metadata": {},
   "source": [
    "The above table shows the first 10 most common words used in positive reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc085908",
   "metadata": {},
   "outputs": [],
   "source": [
    "testReview = CountVectorizer(analyzer=rm).fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a70e8c0",
   "metadata": {},
   "source": [
    "Below we are testing a random review. First, we see the size of the review is 17734 characters. Then the review is vectorized and we see that transform is used so that it goes through each word in the review to see how many unique words there are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaec186",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing random review, review as a vector (another way for BOW)\n",
    "#size of review\n",
    "print(len(testReview.vocabulary_))\n",
    "rev43 = X[43]\n",
    "print(rev43)\n",
    "test1 = testReview.transform([rev43])\n",
    "print(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8f2315",
   "metadata": {},
   "outputs": [],
   "source": [
    "#words that are most common, in this review we can read that the drinks are sweet\n",
    "print(testReview.get_feature_names_out()[8504])\n",
    "print(testReview.get_feature_names_out()[15955])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca07279",
   "metadata": {},
   "source": [
    "Here we are transforming data X into sparse matrix to speed up processing since there are many zero occurences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54813a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = testReview.transform(X)\n",
    "#shape of the matrix:\n",
    "print(\"Shape of the sparse matrix: \", X.shape)\n",
    "#non-zero occurences:\n",
    "print(\"Non-Zero occurences: \",X.nnz)\n",
    "\n",
    "#new density of matrix\n",
    "density = (X.nnz/(X.shape[0]*X.shape[1]))*100\n",
    "print(\"Density of the matrix = \",density)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eeeee8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorization\n",
    "vect = CountVectorizer(stop_words=stopwords.words('english'))\n",
    "vect.fit(posneg.text)\n",
    "X = vect.transform(posneg.text)\n",
    "X_df = pd.DataFrame(X.toarray(), columns=vect.get_feature_names_out())\n",
    "\n",
    "# define the vector of targets \n",
    "# matrix of features\n",
    "y = posneg.Sentiment\n",
    "X = X_df\n",
    "# # Perform the train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042110f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#k nearest neighbor\n",
    "knn = KNeighborsClassifier(n_neighbors=10)\n",
    "knn.fit(X_train,y_train)\n",
    "predknn = knn.predict(X_test)\n",
    "print(\"Confusion Matrix for K Nearest Neighbors:\")\n",
    "print(confusion_matrix(y_test,predknn))\n",
    "print(\"Score: \",round(accuracy_score(y_test,predknn)*100,2))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test,predknn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdec06d",
   "metadata": {},
   "source": [
    "Above are the confusion matrix and accuracy score for K nearest neighbors, we can see that the score has an accuracy of 98.14% which is high. We will use test this to predict whether a review is positive or negative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e569c571",
   "metadata": {},
   "source": [
    "Below we are predicting a positive or negative review using KNN. The review below is positive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb72e3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "posrev = posneg['text'][0]\n",
    "print(\"Positive review: \", posrev)\n",
    "print(\"Star Rating: \", posneg['stars'][0])\n",
    "posrev_t = vect.transform([posrev])\n",
    "knn.predict(posrev_t)\n",
    "\n",
    "#look at first number\n",
    "#1 = positive, 2 = negative\n",
    "print(\"Predicted Pos/Neg Rating (second column):\")\n",
    "print(posrev_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df9e82d",
   "metadata": {},
   "source": [
    "Below we are predicting a positive or negative review using KNN. The review below is negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e3dd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "negrev = posneg['text'][562]\n",
    "print(\"Negative review: \", negrev)\n",
    "print(\"Star Rating: \", neg['stars'][562])\n",
    "negrev_t = vect.transform([negrev])\n",
    "knn.predict(negrev_t)\n",
    "\n",
    "#look at first number\n",
    "#1 = positive, 2 = negative\n",
    "print(\"Predicted Pos/Neg Rating (second column):\")\n",
    "print(negrev_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d138b25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e00501-95ff-4c32-bb02-24fc655c7fc0",
   "metadata": {},
   "source": [
    "# Text Mining with Naïve Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7046617-b824-47df-ad01-38329b9cf433",
   "metadata": {
    "tags": []
   },
   "source": [
    "Using naïve bayes, we are trying to predict whether a review is negative or positive and what rating the user will give for that business."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dbd9d5-56b4-4b06-9e7c-4a3bbe48cc49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#converting text into tokens\n",
    "vectorizer = CountVectorizer(stop_words='english', ngram_range = (1,1), max_df = .80, min_df = 4)\n",
    "#train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[\"text\"], df[\"Sentiment\"],random_state=1, test_size= 0.2)\n",
    "#transforming the tokens into counts\n",
    "vect.fit(X_train)\n",
    "X_train_dtm = vect.transform(X_train) \n",
    "X_test_dtm = vect.transform(X_test)\n",
    "NB = MultinomialNB()\n",
    "NB.fit(X_train_dtm, y_train)\n",
    "y_pred = NB.predict(X_test_dtm)\n",
    "print('Naïve Bayes')\n",
    "print()\n",
    "print('Accuracy Score: ',metrics.accuracy_score(y_test,y_pred)*100,'%',sep='')\n",
    "print()\n",
    "print(\"Test Review: \", vals[2])\n",
    "print()\n",
    "print(\"Predicted Sentiment for Review: \", y_pred[2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
